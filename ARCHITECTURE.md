# Agentic Fraud Detection Framework - Complete Architecture

## End-to-End Overview

This document explains the complete architecture and workflow of the Agentic Fraud Detection Framework, from Databricks setup to pattern execution and tool management.

---

## üèóÔ∏è Architecture Diagram

```mermaid
flowchart TB
    subgraph User["üë§ User"]
        PatternJSON["patterns.json<br/>Fraud Detection Pattern"]
        ENV[".env<br/>Configuration"]
    end

    subgraph LocalSystem["üíª Local System"]
        subgraph AgenticFramework["ü§ñ Agentic Framework (LangGraph)"]
            Main["main.py / run_auto.py<br/>Entry Point"]
            Workflow["workflow.py<br/>LangGraph StateGraph"]
            State["state.py<br/>AgentState Management"]
            
            subgraph Nodes["üì¶ Workflow Nodes"]
                N1["parse_pattern"]
                N2["generate_sql"]
                N3["await_sql_approval"]
                N4["execute_step"]
                N5["await_execution_feedback"]
                N6["store_step_sql"]
                N7["next_step"]
                N8["combine_to_function"]
                N9["execute_final"]
                N10["await_final_approval"]
                N11["insert_tool"]
                N12["complete"]
            end
        end
        
        subgraph Tools["üîß Tools"]
            GenieTool["genie_tool.py<br/>Databricks Genie API"]
            SQLExecutor["sql_executor.py<br/>Databricks SQL Connector"]
            SQLStorage["sql_storage.py<br/>Local MD Storage"]
        end
        
        Config["config.py<br/>Configuration Loader"]
        Output["output/sqlcode.md<br/>Generated SQL"]
    end

    subgraph Cloud["‚òÅÔ∏è Cloud Services"]
        subgraph Anthropic["üß† Anthropic API"]
            Claude["Claude 4<br/>(claude-sonnet-4-20250514)"]
        end
        
        subgraph Databricks["üî∂ Databricks"]
            subgraph GenieSpace["Genie Space"]
                Genie["AI/BI Genie<br/>NLP to SQL"]
            end
            
            subgraph SQLWarehouse["SQL Warehouse"]
                DBSQL["SQL Execution Engine"]
            end
            
            subgraph UnityCatalog["Unity Catalog"]
                subgraph Catalog["fraud_detection"]
                    subgraph PolicySchema["policies (schema)"]
                        PoliciesTable["policies<br/>Policy Definitions"]
                        PatternsTable["patterns<br/>Fraud Patterns"]
                        ToolsTable["sql_tools<br/>Generated SQL Tools"]
                    end
                    
                    subgraph TestSchema["test_data (schema)"]
                        ClaimsTable["claims<br/>Medical Claims"]
                        ProvidersTable["providers<br/>Healthcare Providers"]
                        ProceduresTable["procedures<br/>Medical Procedures"]
                    end
                end
            end
        end
    end

    %% Connections
    User --> Main
    ENV --> Config
    PatternJSON --> Main
    Main --> Workflow
    Workflow --> State
    Workflow --> Nodes
    
    N2 --> GenieTool
    N2 --> Claude
    N4 --> SQLExecutor
    N6 --> SQLStorage
    N11 --> SQLExecutor
    
    GenieTool --> Genie
    SQLExecutor --> DBSQL
    DBSQL --> UnityCatalog
    
    SQLStorage --> Output
    
    N11 --> ToolsTable
    N4 --> ClaimsTable

    style Claude fill:#8B5CF6,color:#fff
    style Databricks fill:#FF6B00,color:#fff
    style ToolsTable fill:#10B981,color:#fff
    style ClaimsTable fill:#3B82F6,color:#fff
```

---

## üìä Workflow Sequence Diagram

```mermaid
sequenceDiagram
    participant User
    participant Main as main.py
    participant Workflow as LangGraph Workflow
    participant Claude as Claude 4 (Anthropic)
    participant Genie as Databricks Genie
    participant DBSQL as Databricks SQL
    participant Storage as SQL Storage
    participant Tools as sql_tools Table

    User->>Main: Start with patterns.json
    Main->>Workflow: Initialize StateGraph
    
    loop For Each Step (1-6)
        Workflow->>Genie: Send NLP prompt
        alt Genie Success
            Genie-->>Workflow: Return SQL
        else Genie Fails
            Workflow->>Claude: Fallback SQL generation
            Claude-->>Workflow: Return SQL
        end
        
        Workflow->>User: Show SQL, await approval
        User-->>Workflow: Approve / Edit / Reject
        
        alt Approved
            Workflow->>DBSQL: Execute SQL
            DBSQL-->>Workflow: Return results
            Workflow->>User: Show results, await feedback
            User-->>Workflow: Results OK
            Workflow->>Storage: Store step SQL
        else Rejected
            Workflow->>Workflow: Regenerate SQL
        end
    end
    
    Workflow->>Claude: Combine all steps into final function
    Claude-->>Workflow: Return combined SQL
    
    Workflow->>DBSQL: Execute final function
    DBSQL-->>Workflow: Return fraudulent claims
    
    Workflow->>User: Final approval
    User-->>Workflow: Approve
    
    Workflow->>Tools: INSERT tool into sql_tools
    Workflow->>Main: Return final state
    Main->>User: Display summary
```

---

## üóÑÔ∏è Databricks Schema and Tables

### Step 1: Catalog and Schema Creation

```sql
-- Create the main catalog
CREATE CATALOG IF NOT EXISTS fraud_detection;

-- Create schemas
CREATE SCHEMA IF NOT EXISTS fraud_detection.policies;
CREATE SCHEMA IF NOT EXISTS fraud_detection.test_data;
```

### Step 2: Policy Tables

#### policies Table
Stores policy definitions that patterns belong to.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.policies.policies (
    policy_id STRING NOT NULL,           -- Primary key: UHC-POL-2026-0005A
    policy_name STRING NOT NULL,         -- "Global Days Policy, Professional"
    policy_number STRING,
    effective_date DATE,
    metadata MAP<STRING, STRING>,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    _change_type STRING,
    _commit_version LONG
) USING DELTA;
```

#### patterns Table
Stores fraud detection patterns with NLP descriptions.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.policies.patterns (
    pattern_id STRING NOT NULL,          -- Primary key: FP-GD-001
    policy_id STRING NOT NULL,           -- Foreign key to policies
    pattern_name STRING NOT NULL,        -- "E/M Services During Global Period..."
    nlp_description STRING,              -- Natural language description
    severity STRING,                     -- HIGH, MEDIUM, LOW, CRITICAL
    status STRING,                       -- active, pending, disabled
    tool_id STRING,                      -- Foreign key to sql_tools (after generation)
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    _change_type STRING,
    _commit_version LONG
) USING DELTA
PARTITIONED BY (policy_id);
```

#### sql_tools Table
Stores generated SQL functions as reusable tools.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.policies.sql_tools (
    tool_id STRING NOT NULL,             -- Primary key: tool_FP-GD-001
    pattern_id STRING NOT NULL,          -- Foreign key to patterns
    policy_id STRING NOT NULL,           -- Foreign key to policies
    sql_query STRING NOT NULL,           -- The actual SQL code
    validation_status STRING,            -- validated, pending, failed
    validated_by STRING,                 -- Who validated it
    validated_at TIMESTAMP,              -- When validated
    last_executed TIMESTAMP,             -- Last execution time
    execution_count LONG DEFAULT 0,      -- How many times executed
    execution_time_ms DOUBLE,            -- Performance metric
    rows_returned LONG,                  -- Result count
    metadata MAP<STRING, STRING>,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    _change_type STRING,
    _commit_version LONG
) USING DELTA
TBLPROPERTIES ('delta.feature.allowColumnDefaults'='supported');
```

### Step 3: Test Data Tables

#### claims Table
Sample medical claims data for fraud detection testing.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.test_data.claims (
    claim_id STRING NOT NULL,            -- CLM001, CLM002, ...
    patient_id STRING NOT NULL,          -- PAT001, PAT002, ...
    provider_npi STRING NOT NULL,        -- 10-digit NPI
    provider_tin STRING NOT NULL,        -- Tax ID
    provider_specialty STRING,           -- Orthopedic, Primary Care, ...
    service_date DATE NOT NULL,          -- Date of service
    procedure_code STRING,               -- CPT codes: 27447, 29881, ...
    global_days_value STRING,            -- '010', '090', '000', 'XXX'
    em_code STRING,                      -- E/M codes: 99213, 99214, ...
    modifier_24 STRING,                  -- NULL if missing (fraud indicator)
    modifier_58 STRING,
    fare_amount DOUBLE,
    claim_status STRING,                 -- pending, paid, denied
    created_at TIMESTAMP
) USING DELTA
PARTITIONED BY (service_date);
```

#### providers Table
Healthcare provider reference data.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.test_data.providers (
    provider_npi STRING NOT NULL,        -- Primary key
    provider_name STRING,
    provider_tin STRING,
    provider_specialty STRING,
    practice_group STRING
) USING DELTA;
```

#### procedures Table
Medical procedure reference data with global days.

```sql
CREATE TABLE IF NOT EXISTS fraud_detection.test_data.procedures (
    procedure_code STRING NOT NULL,      -- Primary key: 27447
    procedure_description STRING,        -- "Total knee arthroplasty"
    global_days_value STRING,            -- '010', '090', '000', 'XXX'
    is_surgical BOOLEAN,
    is_em BOOLEAN,
    category STRING
) USING DELTA;
```

---

## üîÑ Complete Execution Flow

### Phase 1: Setup (QUICK_START_DATABRICKS.md)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 1: Create Databricks Infrastructure                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Create catalog: fraud_detection                              ‚îÇ
‚îÇ  ‚Ä¢ Create schemas: policies, test_data                          ‚îÇ
‚îÇ  ‚Ä¢ Create tables: policies, patterns, sql_tools                 ‚îÇ
‚îÇ  ‚Ä¢ Create tables: claims, providers, procedures                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 2: Load Test Data                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Insert sample claims (8 records)                             ‚îÇ
‚îÇ  ‚Ä¢ Insert providers (3 records)                                 ‚îÇ
‚îÇ  ‚Ä¢ Insert procedures (5 records)                                ‚îÇ
‚îÇ  ‚Ä¢ Include fraud pattern examples (CLM001 - missing modifier)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 3: Load Policy and Patterns                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Insert policy: UHC-POL-2026-0005A                            ‚îÇ
‚îÇ  ‚Ä¢ Insert patterns: FP-GD-001, FP-GD-002                        ‚îÇ
‚îÇ  ‚Ä¢ Each pattern has NLP description and severity                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 2: Agentic Framework Execution

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 4: Initialize Agentic Framework                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Load .env configuration                                      ‚îÇ
‚îÇ  ‚Ä¢ Initialize Claude 4 (Anthropic)                              ‚îÇ
‚îÇ  ‚Ä¢ Initialize Databricks Genie tool                             ‚îÇ
‚îÇ  ‚Ä¢ Initialize SQL Executor                                      ‚îÇ
‚îÇ  ‚Ä¢ Create LangGraph StateGraph                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 5: Process Pattern (6 Detection Steps)                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  For each step in pattern.detection_logic:                      ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ    ‚îÇ 1. Generate SQL (Genie ‚Üí Claude fallback)             ‚îÇ   ‚îÇ
‚îÇ    ‚îÇ 2. Human Review (approve/edit/reject)                 ‚îÇ   ‚îÇ
‚îÇ    ‚îÇ 3. Execute SQL against Databricks                     ‚îÇ   ‚îÇ
‚îÇ    ‚îÇ 4. Human Feedback on results                          ‚îÇ   ‚îÇ
‚îÇ    ‚îÇ 5. Store approved SQL                                 ‚îÇ   ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Step 1: Identify surgical procedures (global_days 010/090)     ‚îÇ
‚îÇ  Step 2: Calculate global period end date                       ‚îÇ
‚îÇ  Step 3: Find E/M services within global period                 ‚îÇ
‚îÇ  Step 4: Filter same provider OR same TIN+specialty             ‚îÇ
‚îÇ  Step 5: Filter missing modifier_24                             ‚îÇ
‚îÇ  Step 6: Return fraudulent claims with details                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 6: Combine into Final Function                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Claude analyzes all 6 step SQLs                              ‚îÇ
‚îÇ  ‚Ä¢ Generates optimized combined SQL with CTEs                   ‚îÇ
‚îÇ  ‚Ä¢ Function name: detect_fp_gd_001                              ‚îÇ
‚îÇ  ‚Ä¢ Execute and show results                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 7: Insert Tool into Database                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ INSERT into fraud_detection.policies.sql_tools               ‚îÇ
‚îÇ  ‚Ä¢ UPDATE fraud_detection.policies.patterns SET tool_id         ‚îÇ
‚îÇ  ‚Ä¢ Tool is now reusable and queryable                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 3: Tool Usage (Post-Execution)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Retrieve and Execute Stored Tool                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  -- Get the tool                                                ‚îÇ
‚îÇ  SELECT sql_query FROM fraud_detection.policies.sql_tools       ‚îÇ
‚îÇ  WHERE tool_id = 'tool_FP-GD-001';                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  -- Execute the stored SQL                                      ‚îÇ
‚îÇ  -- (Copy sql_query and run it)                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  -- Track executions                                            ‚îÇ
‚îÇ  UPDATE fraud_detection.policies.sql_tools                      ‚îÇ
‚îÇ  SET execution_count = execution_count + 1,                     ‚îÇ
‚îÇ      last_executed = CURRENT_TIMESTAMP()                        ‚îÇ
‚îÇ  WHERE tool_id = 'tool_FP-GD-001';                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ File Structure

```
demo/agentic_fraud_detection/
‚îú‚îÄ‚îÄ üìÑ main.py                 # Interactive mode entry point
‚îú‚îÄ‚îÄ üìÑ run_auto.py             # Auto-approval mode
‚îú‚îÄ‚îÄ üìÑ insert_tool.py          # Standalone tool insertion
‚îú‚îÄ‚îÄ üìÑ quick_test.py           # Local simulation
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Core Framework
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ workflow.py         # LangGraph StateGraph (749 lines)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ state.py            # AgentState TypedDict
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ config.py           # Environment configuration
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ genie_tool.py       # Databricks Genie API wrapper
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sql_executor.py     # Databricks SQL execution
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ sql_storage.py      # Local SQL storage (markdown)
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Configuration
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ .env                # Your credentials (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ env.template        # Template for credentials
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ patterns.json       # Fraud detection patterns
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Output
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ output/sqlcode.md   # Generated SQL code
‚îÇ
‚îî‚îÄ‚îÄ üì¶ Documentation
    ‚îú‚îÄ‚îÄ üìÑ README.md           # Quick start guide
    ‚îî‚îÄ‚îÄ üìÑ ARCHITECTURE.md     # This file
```

---

## üîê Security & Configuration

### Environment Variables (.env)

```env
# Databricks
DATABRICKS_HOST=https://dbc-xxxxx.cloud.databricks.com
DATABRICKS_TOKEN=dapi_xxxxx

# Genie Space
GENIE_SPACE_ID=01f0e8ce532d1222823b0987645f6138

# SQL Warehouse
DBSQL_SERVER_HOSTNAME=dbc-xxxxx.cloud.databricks.com
DBSQL_HTTP_PATH=/sql/1.0/warehouses/xxxxx

# LLM (Anthropic Claude 4)
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Output
OUTPUT_DIR=./output
SQL_CODE_FILE=sqlcode.md
```

---

## üìà Fraud Detection Results

### Pattern: FP-GD-001

**E/M Services During Global Period Without Modifier 24**

| Field | Value |
|-------|-------|
| Claim ID | CLM001 |
| Patient | PAT001 |
| Provider NPI | 1234567890 |
| E/M Code | 99213 |
| Service Date | 2024-01-20 |
| Surgical Procedure | 27447 (Total Knee Arthroplasty) |
| Global Days | 090 |
| Modifier 24 | **NULL (MISSING - FRAUD!)** |

**Interpretation:** An E/M service was billed during the 90-day global period of a surgical procedure without modifier 24, indicating the E/M was related to the surgery and should not be separately billed.

---

## üîÑ LangGraph State Machine

```mermaid
stateDiagram-v2
    [*] --> parse_pattern
    parse_pattern --> generate_sql
    
    generate_sql --> await_sql_approval
    
    await_sql_approval --> execute_step: Approved
    await_sql_approval --> generate_sql: Rejected
    await_sql_approval --> await_sql_approval: Edit
    
    execute_step --> await_execution_feedback
    
    await_execution_feedback --> store_step_sql: Results OK
    await_execution_feedback --> generate_sql: Results Bad
    
    store_step_sql --> next_step
    
    next_step --> generate_sql: More Steps
    next_step --> combine_to_function: All Steps Done
    
    combine_to_function --> execute_final
    execute_final --> await_final_approval
    
    await_final_approval --> insert_tool: Approved
    await_final_approval --> rethink: Rejected
    
    rethink --> combine_to_function
    
    insert_tool --> complete
    complete --> [*]
```

---

## üéØ Key Technologies

| Technology | Purpose | Version |
|------------|---------|---------|
| **LangGraph** | Workflow orchestration | ‚â•0.2.0 |
| **Claude 4 (Anthropic)** | SQL generation | claude-sonnet-4-20250514 |
| **Databricks Genie** | NLP to SQL | - |
| **Databricks SQL Connector** | Query execution | ‚â•3.0.0 |
| **Delta Lake** | Data storage | - |
| **Unity Catalog** | Data governance | - |
| **Python** | Runtime | 3.12 |

---

## üöÄ Quick Commands

```bash
# Auto-run mode (no interaction)
python run_auto.py

# Interactive mode (human-in-the-loop)
python main.py

# Insert tool only (after successful run)
python insert_tool.py

# Local simulation (no Databricks)
python quick_test.py
```

---

## ‚úÖ Success Criteria

The framework is successful when:

1. ‚úÖ All 6 detection steps generate valid SQL
2. ‚úÖ SQL executes against Databricks without errors
3. ‚úÖ Fraudulent claims are correctly identified
4. ‚úÖ Final function is combined and optimized
5. ‚úÖ Tool is inserted into sql_tools table
6. ‚úÖ Pattern is updated with tool_id reference
7. ‚úÖ SQL code is saved to output/sqlcode.md
